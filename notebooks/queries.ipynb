{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from configparser import ConfigParser\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParser()\n",
    "config.read('settings.cfg')\n",
    "\n",
    "USUARIO_HDFS = config.get('local', 'usuario_hdfs')\n",
    "TOPICO_KAFKA = config.get('local', 'topico_kafka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando cabeçalhos dos CSVs retornados mesmo com skip headers definido na tabela.\n",
    "# Bug relacionado: https://issues.apache.org/jira/browse/SPARK-11374\n",
    "base_df = spark.read.table('hist_painel_covidbr').filter('regiao != \"regiao\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.75 ms, sys: 0 ns, total: 7.75 ms\n",
      "Wall time: 74.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Visualização 1: Casos recuperados & acompanhamento\n",
    "v1_df = (base_df\n",
    "    .filter(\"coduf = 76\")\n",
    "    .select(\"data\", \"recuperadosnovos\", \"emacompanhamentonovos\")\n",
    "    .withColumnRenamed(\"recuperadosnovos\", \"recuperados\")\n",
    "    .withColumnRenamed(\"emacompanhamentonovos\", \"em_acompanhamento\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 ms, sys: 100 µs, total: 10.2 ms\n",
      "Wall time: 404 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Visualização 2: Casos confirmados\n",
    "v2_df = (base_df\n",
    "    .filter(\"coduf = 76\")\n",
    "    .select(\"data\", \"casosacumulado\", \"casosnovos\", \"populacaotcu2019\")\n",
    "    .withColumn(\n",
    "        \"incidencia\",\n",
    "        round(col(\"casosacumulado\").cast(\"double\") * 100000 / col(\"populacaotcu2019\").cast(\"double\"), 1)\n",
    "    )\n",
    "    .withColumnRenamed(\"casosacumulado\", \"acumulado\")\n",
    "    .withColumnRenamed(\"casosnovos\", \"casos_novos\")\n",
    "    .drop(\"populacaotcu2019\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.04 ms, sys: 6.24 ms, total: 10.3 ms\n",
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Visualização 3: Óbitos\n",
    "v3_df = (base_df\n",
    "    .filter(\"coduf = 76\")\n",
    "    .select(\"data\", \"obitosacumulado\", \"obitosnovos\", \"populacaotcu2019\", \"casosacumulado\")\n",
    "    .withColumn(\n",
    "        \"letalidade\",\n",
    "        round(col(\"obitosacumulado\") / col(\"casosacumulado\") * 100, 1)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"mortalidade\",\n",
    "        round(col(\"obitosacumulado\").cast(\"double\") * 100000 / col(\"populacaotcu2019\").cast(\"double\"), 1)\n",
    "    )\n",
    "    .withColumnRenamed(\"obitosacumulado\", \"obitos_acumulados\")\n",
    "    .withColumnRenamed(\"obitosnovos\", \"obitos_novos\")\n",
    "    .drop(\"casosacumulado\", \"populacaotcu2019\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.9 ms, sys: 1.25 ms, total: 26.1 ms\n",
      "Wall time: 248 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Visualização 4: casos/obitos/incidencia/mortalidade/atualização por região/brasil\n",
    "v4_df = (base_df\n",
    " .filter(\"codmun is null\")\n",
    " .select(\"data\", \"regiao\", \"estado\", \"casosacumulado\", \"obitosacumulado\", \"populacaotcu2019\")\n",
    " .groupBy(\"data\", \"regiao\")\n",
    " .agg(\n",
    "     sum(\"casosacumulado\").alias(\"casos\"),\n",
    "     sum(\"obitosacumulado\").alias(\"obitos\"),\n",
    "     sum(\"populacaotcu2019\").alias(\"populacao\")\n",
    " )\n",
    " .withColumn(\n",
    "    \"incidencia\",\n",
    "    round(col(\"casos\").cast(\"double\") * 100000 / col(\"populacao\").cast(\"double\"), 1)\n",
    " )\n",
    " .withColumn(\n",
    "    \"mortalidade\",\n",
    "    round(col(\"obitos\").cast(\"double\") * 100000 / col(\"populacao\").cast(\"double\"), 1)\n",
    " )\n",
    " .drop(\"populacao\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_df.write.format('orc').saveAsTable('covid_casos_recuperados_acompanhamento', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_df.write.option('compression', 'snappy').save(f'/user/{USUARIO_HDFS}/covid_casos_confirmados', format='parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(v3_df\n",
    "    .selectExpr(\"to_json(struct(*)) as value\")\n",
    "    .write\n",
    "    .format(\"kafka\") \n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\")\\\n",
    "    .option(\"topic\", TOPICO_KAFKA) \\\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_df.write.save(f'/user/{USUARIO_HDFS}/covid_casos_regiao', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(v1_df.orderBy(col(\"data\").desc()).toPandas())\n",
    "display(v2_df.orderBy(col(\"data\").desc()).toPandas())\n",
    "display(v3_df.orderBy(col(\"data\").desc()).toPandas())\n",
    "display(v4_df.orderBy(col(\"data\").desc(), col(\"regiao\")).toPandas())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
